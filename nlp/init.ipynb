{
 "cells": [
  {
   "cell_type": "code",
   "id": "fe70d899",
   "metadata": {},
   "source": [
    "import torch, platform, sys, subprocess\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"OS:\", platform.platform())\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA?\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA capability:\", torch.cuda.get_device_capability(0))\n",
    "\n",
    "try:\n",
    "    out = subprocess.check_output([\"nvidia-smi\"], text=True)\n",
    "    print(\"\\n=== nvidia-smi ===\\n\", out)\n",
    "except Exception as e:\n",
    "    print(\"nvidia-smi not available:\", e)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1f5a62ef6aedd828",
   "metadata": {},
   "source": [
    "import json, pathlib, random, uuid\n",
    "\n",
    "DATA_DIR = pathlib.Path(\"data\")\n",
    "RAW = DATA_DIR/\"raw\"\n",
    "OUT = DATA_DIR/\"train.jsonl\"\n",
    "RAW.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def controls_to_prompt(ctrl):\n",
    "    parts = [\n",
    "        f\"topics={','.join(ctrl['topics'])}\",\n",
    "        f\"difficulty={ctrl['difficulty']}\",\n",
    "        f\"length={ctrl['length']}\",\n",
    "        f\"format={'+'.join(ctrl['format'])}\",\n",
    "    ]\n",
    "    return \"; \".join(parts)\n",
    "\n",
    "def load_api_like_examples():\n",
    "    exams = []\n",
    "    for p in RAW.glob(\"*.json\"):\n",
    "        with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "            obj = json.load(f)\n",
    "            exams.append(obj)\n",
    "    return exams\n",
    "\n",
    "def normalize_exam(exam_items):\n",
    "    lines = []\n",
    "    for it in exam_items:\n",
    "        id_ = it.get(\"id\") or it.get(\"qid\") or it.get(\"number\") or \"?\"\n",
    "        text = it.get(\"text\") or it.get(\"question\") or \"\"\n",
    "        lines.append(f\"{id_}. {text}\".strip())\n",
    "        if it.get(\"options\"):\n",
    "            for opt in it[\"options\"]:\n",
    "                lines.append(f\"- {opt}\")\n",
    "    return \"\\n\".join(lines).strip()\n",
    "\n",
    "placeholder_exam = [\n",
    "    {\"id\": 1, \"text\": \"Solve for x: 2x + 3 = 11\", \"type\": \"open_answer\", \"options\": [\"x=3\",\"x=4\",\"x=5\",\"x=2\"], \"answer\": \"x=4\", \"subquestions\": None}\n",
    "]\n",
    "(RAW/\"placeholder.json\").write_text(json.dumps(placeholder_exam, ensure_ascii=False, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "random.seed(7)\n",
    "exams = load_api_like_examples()\n",
    "topic_pools = [[\"algebra\",\"linear-equations\"],[\"calculus\",\"derivatives\"],[\"physics\",\"kinematics\"],[\"biology\",\"photosynthesis\"]]\n",
    "difficulties = [\"easy\",\"medium\",\"hard\"]\n",
    "formats = [[\"multiple_choice\"],[\"multiple_choice\",\"short\"],[\"multiple_choice\",\"long\"],[\"open_answer\"]]\n",
    "\n",
    "records = []\n",
    "for ex in exams:\n",
    "    prompt = controls_to_prompt({\n",
    "        \"topics\": random.choice(topic_pools),\n",
    "        \"difficulty\": random.choice(difficulties),\n",
    "        \"length\": random.choice([8,10,12]),\n",
    "        \"format\": random.choice(formats)\n",
    "    })\n",
    "    input_text = \"Exam format:\\n\" + normalize_exam(ex)\n",
    "    target = normalize_exam(ex)\n",
    "    records.append({\"id\": str(uuid.uuid4()), \"prompt\": prompt, \"input\": input_text, \"output\": target})\n",
    "\n",
    "OUT.write_text(\"\\n\".join(json.dumps(r, ensure_ascii=False) for r in records), encoding=\"utf-8\")\n",
    "len(records), str(OUT)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9207912d914be51",
   "metadata": {},
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import T5ForConditionalGeneration, T5TokenizerFast, DataCollatorForSeq2Seq, Trainer, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import torch\n",
    "\n",
    "MODEL_NAME = \"t5-small\"\n",
    "DATA_PATH = \"data/train.jsonl\"\n",
    "OUT_DIR = \"out-t5-lora\"\n",
    "\n",
    "def format_example(ex):\n",
    "    src = f\"controls: {ex['prompt']}\\n\\nexemplars:\\n{ex['input']}\\n\\n# task: generate new exam as JSON\"\n",
    "    tgt = ex[\"output\"]\n",
    "    return {\"src\": src, \"tgt\": tgt}\n",
    "\n",
    "tok = T5TokenizerFast.from_pretrained(MODEL_NAME)\n",
    "base = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "\n",
    "lora = LoraConfig(r=16, lora_alpha=32, lora_dropout=0.05, bias=\"none\", task_type=\"SEQ_2_SEQ_LM\", target_modules=[\"q\",\"v\"])\n",
    "model = get_peft_model(base, lora)\n",
    "\n",
    "ds = load_dataset(\"json\", data_files=DATA_PATH, split=\"train\")\n",
    "ds = ds.map(format_example)\n",
    "\n",
    "max_src_len = 1024\n",
    "max_tgt_len = 1024\n",
    "\n",
    "def tok_map(batch):\n",
    "    mi = tok(batch[\"src\"], max_length=max_src_len, truncation=True)\n",
    "    labels = tok(batch[\"tgt\"], max_length=max_tgt_len, truncation=True)\n",
    "    mi[\"labels\"] = labels[\"input_ids\"]\n",
    "    return mi\n",
    "\n",
    "ds = ds.map(tok_map, batched=True, remove_columns=ds.column_names)\n",
    "collator = DataCollatorForSeq2Seq(tokenizer=tok, model=model)\n",
    "\n",
    "args = TrainingArguments(output_dir=OUT_DIR, num_train_epochs=1, per_device_train_batch_size=2, gradient_accumulation_steps=8, learning_rate=2e-4, warmup_ratio=0.03, logging_steps=10, save_strategy=\"epoch\", bf16=torch.cuda.is_available(), fp16=False, optim=\"adamw_torch\", report_to=\"none\")\n",
    "\n",
    "trainer = Trainer(model=model, args=args, train_dataset=ds, data_collator=collator)\n",
    "\n",
    "trainer.train()\n",
    "model.save_pretrained(OUT_DIR)\n",
    "tok.save_pretrained(OUT_DIR)\n",
    "print(\"Dumped\", OUT_DIR)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "69672102",
   "metadata": {},
   "source": [
    "import json, re\n",
    "from transformers import T5ForConditionalGeneration, T5TokenizerFast\n",
    "from jsonschema import Draft7Validator\n",
    "\n",
    "CKPT = \"out-t5-lora\"\n",
    "\n",
    "exam_schema = {\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"metadata\": {\n",
    "      \"type\": \"object\",\n",
    "      \"properties\": {\n",
    "        \"topics\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "        \"difficulty\": {\"type\": \"string\"},\n",
    "        \"length\": {\"type\": \"integer\"},\n",
    "        \"format\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
    "      },\n",
    "      \"required\": [\"topics\",\"difficulty\",\"length\",\"format\"]\n",
    "    },\n",
    "    \"questions\": {\n",
    "      \"type\": \"array\",\n",
    "      \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"id\": {\"type\": \"integer\"},\n",
    "          \"text\": {\"type\": \"string\"},\n",
    "          \"type\": {\"type\": \"string\"},\n",
    "          \"options\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}}\n",
    "        },\n",
    "        \"required\": [\"id\",\"text\",\"type\"]\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"required\": [\"metadata\",\"questions\"]\n",
    "}\n",
    "\n",
    "tok = T5TokenizerFast.from_pretrained(CKPT)\n",
    "model = T5ForConditionalGeneration.from_pretrained(CKPT)\n",
    "\n",
    "def generate_json_exam(topics, difficulty, length, fmt, retries=2):\n",
    "    prompt = f\"topics={','.join(topics)}; difficulty={difficulty}; length={length}; format={'+'.join(fmt)}\"\n",
    "    exemplar = \"\"\"\\\n",
    "    ```json\n",
    "    {\n",
    "      \"metadata\": {\n",
    "        \"topics\": [\"algebra\",\"linear-equations\"],\n",
    "        \"difficulty\": \"medium\",\n",
    "        \"length\": 2,\n",
    "        \"format\": [\"mcq\"]\n",
    "      },\n",
    "      \"questions\": [\n",
    "        {\"id\": 1, \"text\": \"Solve for x: 3x - 5 = 16.\", \"type\": \"mcq\",\n",
    "         \"options\": [\"x = 7\", \"x = 6\", \"x = 5\", \"x = 4\"]},\n",
    "        {\"id\": 2, \"text\": \"Which is linear?\", \"type\": \"mcq\",\n",
    "         \"options\": [\"y = 2x + 1\", \"y = x^2\", \"y = sin x\", \"y = 2^x\"]}\n",
    "      ]\n",
    "    }\n",
    "    ```\"\"\"\n",
    "    src = (\n",
    "        \"controls: \" + prompt + \"\\n\\n\"\n",
    "        \"You are an exam generator. Output MUST be a single fenced JSON block and NOTHING else.\\n\"\n",
    "        \"Keys: metadata{topics,difficulty,length,format}, questions[list of {id,text,type,options?}].\\n\"\n",
    "        \"No prose, no headings, no backticks outside the JSON fence. Do not echo the prompt.\\n\\n\"\n",
    "        \"Example format:\\n\" + exemplar + \"\\n\\n\"\n",
    "        \"# task: generate a new exam in JSON for the given controls\"\n",
    "    )\n",
    "    for attempt in range(retries + 1):\n",
    "        inp = tok(src, return_tensors=\"pt\").to(model.device)\n",
    "        out = model.generate(\n",
    "            **inp, max_new_tokens=900,\n",
    "            do_sample=False, num_beams=4, length_penalty=0.8, early_stopping=True\n",
    "        )\n",
    "        text = tok.decode(out[0], skip_special_tokens=True).strip()\n",
    "\n",
    "        m = re.search(r\"```json\\s*(\\{[\\s\\S]*?\\})\\s*```\", text, flags=re.IGNORECASE)\n",
    "        json_text = m.group(1) if m else (text if text.startswith(\"{\") and text.endswith(\"}\") else \"\")\n",
    "\n",
    "        if json_text:\n",
    "            try:\n",
    "                obj = json.loads(json_text)\n",
    "                # validate\n",
    "                v = Draft7Validator(exam_schema)\n",
    "                errs = sorted(v.iter_errors(obj), key=lambda e: e.path)\n",
    "                if not errs and obj.get(\"questions\"):\n",
    "                    return obj, errs, text\n",
    "            except Exception:\n",
    "                pass\n",
    "        src += \"\\n\\nRemember: Output only fenced JSON; do not echo the controls.\"\n",
    "\n",
    "    raise ValueError(\"Model did not return valid fenced JSON. Try lowering creativity or improving training data.\")\n",
    "\n",
    "obj, errs, raw_text = generate_json_exam([\"algebra\",\"linear-equations\"], \"hard\", 16, [\"mcq\",\"short\"])\n",
    "\n",
    "print(\"Raw out:\")\n",
    "print(raw_text)\n",
    "print(\"\\nValidation errors:\", len(errs))\n",
    "for e in errs[:5]:\n",
    "    print(\"-\", \"/\".join(map(str,e.path)), \":\", e.message)\n",
    "\n",
    "print(\"\\nJSON:\")\n",
    "print(json.dumps(obj, indent=2, ensure_ascii=False))"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
